# -*- coding: utf-8 -*-
"""image-caption-generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wLpa3QpcImmk-LU7R4Mix4lf34YC5Nbg
"""

!pip install transformers torch Pillow

import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import requests
from io import BytesIO

processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base").to("cuda" if torch.cuda.is_available() else "cpu")

def generate_caption(image):
    inputs = processor(images=image, return_tensors="pt").to("cuda" if torch.cuda.is_available() else "cpu")
    out = model.generate(**inputs)
    return processor.decode(out[0], skip_special_tokens=True)

# Upload image
from google.colab import files
uploaded = files.upload()

image_path = list(uploaded.keys())[0]
img = Image.open(image_path).convert("RGB")
img.show()
print("Caption:", generate_caption(img))

from google.colab import files
uploaded = files.upload()

image_path = list(uploaded.keys())[0]
img = Image.open(image_path).convert("RGB")
img.show()
print("Caption:", generate_caption(img))

from google.colab import files
from PIL import Image
uploaded = files.upload()

image_path = list(uploaded.keys())[0]
img = Image.open(image_path).convert("RGB")
img.show()
print("Caption:", generate_caption(img))

!git config --global user.email "sharanya.23bce8915@vitapstudent.ac.in"
!git config --global user.name "sharanya-lagishetty"
!git clone https://github.com/sharanya-lagishetty/image-caption.git
# Move your notebook to the cloned repo directory, then:
!cd image-caption
!git add your_notebook.ipynb
!git commit -m "Add notebook from Colab"
!git push